---
title: "Pepe Annual Data Analysis"
author: "Michelle DePrenger-Levin"
date: "2024-06-26"
output: R script
---


Transect 15: tag lost so new origin tag put in. Transect 15 starts new in 2024
Transect 16 lost completely. No data for Transect 16

2024    
```{r}

rm(list=ls())
library(R2jags)
library(runjags)
library(mcmcplots)
library(boot)
library(dplyr)
library(tidyr)
library(ggplot2)
library(patchwork)
library(RMark)

library(myClim)

```


Import data     

Move to GitHub once checked and correct  
```{r}

trans2024 <- read.csv("C:/Users/deprengm/Denver Botanic Gardens/Conservation - General/AllProjectsBySpecies/Penstemon-penlandii/Penstemon-penlandii_Projects/Tri-State_Transplant_2023-2026/Data/20240711_dbExport/20240711__pepe_triState_transects.csv", header = TRUE)

## Once this gets corrected, for now use old
plants2024 <- read.csv("C:/Users/deprengm/Denver Botanic Gardens/Conservation - General/AllProjectsBySpecies/Penstemon-penlandii/Penstemon-penlandii_Projects/Tri-State_Transplant_2023-2026/Data/20240711_dbExport/20240711__pepe_triState_plants.csv", header = TRUE)

data2024 <- read.csv("C:/Users/deprengm/Denver Botanic Gardens/Conservation - General/AllProjectsBySpecies/Penstemon-penlandii/Penstemon-penlandii_Projects/Tri-State_Transplant_2023-2026/Data/20240711_dbExport/20240711_pepe_triState_data.csv")

## Missed because duplicate PlantID These seeming duplicates are from two different teams Might have to add a record
# data2024$plantID[data2024$id == 1561] <- 1752
# Missing 1753 from 0.25, 1.25 transect 38 from 2024 - done in MySQL

## 

surv2023_2024 <- data2024 %>%
  left_join(plants2024, by = "plantID")


surv2023_2024 %>%
  filter(plantID == 1753 | (transectID == 38 & transectPosition == 4))
```


# Check correct assigment of PlantIDs to transplants (and subsequently all of them)   
```{r}

table(surv2023_2024$date, surv2023_2024$transplantSeason)

surv2023_2024 %>%
  filter(transplantSeason == "Fall" & date == "2023-05-31")

surv2023_2024 %>%
  filter(plantID %in% c(118,1752))


### Change all dates to one in spring, one in fall and one in 2024 
surv2023_2024 <- surv2023_2024 %>%
  mutate(date = case_when(date == "2023-10-17" ~ "2023-10-16",
                          date == "2024-06-25" ~ "2024-06-24",
                          TRUE ~ date))
## Now looks good
table(surv2023_2024$date, surv2023_2024$transplantSeason)

## Remove Transect 16

surv2023_2024 <- surv2023_2024 %>%
  filter(transectID != 16)
```



# Survival   
```{r}

# Was it transect 16 that was lost? 
## plantID 1752 didn't carry the data with it that is needed, not a new record for each recording 
# plantid 1753, the other duplicate that needed repeating also didn't carry the data with it to each survey
## plantID 118 is at (0.8, 3.65)

surv2023_2024 %>%
  filter(plantID %in% c(1752,1753))

data2024 %>%
  filter(plantID %in% c(118,1752,1753))


# wide format for detection
surv_wide <- surv2023_2024 %>%
  mutate(Date = as.Date(date)) %>%
  filter(!(transectID %in% c(15,16))) %>%
  arrange(Date) %>%
  ## Can ignore the 5 repeat collections of Fall transplants
  filter(recordedBy != "Michelle DePrenger-Levin, Adriana Jacobi") %>%
  mutate(ch = case_when(heightInCentimeters > 0 ~ 1,
                        heightInCentimeters == 0 ~ 0)) %>%
  mutate(Survey = case_when(date == "2023-05-31" ~ "aSp23",
                            date == "2023-10-16" ~ "bFa23",
                            date == "2024-06-24" ~ "cSm24")) %>%
  mutate(Obsr = case_when(recordedBy == "Michelle DePrenger-Levin" ~ "MEDL",
                          # recordedBy == "Michelle DePrenger-Levin, Adriana Jacobi" ~ "MEDL_AJ",
                          recordedBy == "Mike Bone, Stanton Schell" ~ "MB_SS",
                          recordedBy == "Arich Fruehling, Leah Veldhuisen" ~ "AF_LV",
                          recordedBy == "Geena Poulter, Michelle DePrenger-Levin" ~ "GP_MEDL",
                          recordedBy == "Michael Guidi, Brooke Washburn, Syed Jalalzai" ~ "MG_BW_SJ")) %>%
  pivot_wider(names_from = c(Survey, Obsr),
              values_from = ch,
              id_cols = c(plantID,transplantSeason,transectID) 
               ,values_fn = function(x) paste(x, collapse = ", ")# first  ## Because why? why are there double for the same date and observers?
              ) %>%
  arrange(transectID,transplantSeason)



### Combine columns across surveys ignoring the NAs  
## Need to add zeros to all the fall transplants during the spring which I think I do with the mutate

surv_wide %>%
  mutate(across(aSp23_MEDL:bFa23_MEDL, replace_na, "0")) %>%
  unite(ch23, aSp23_MEDL:bFa23_MEDL , sep = "") %>% 
  unite(ch24, cSm24_MB_SS:cSm24_MG_BW_SJ, sep = "") %>%
  unite(ch, ch23:ch24, sep = "") %>%
  filter(nchar(ch) < 11) %>%
  left_join(plants2024, by = "plantID") %>%
  left_join(data2024, by = "plantID")
  
pepe_ch <- surv_wide %>%
  mutate(across(aSp23_MEDL:bFa23_MEDL, replace_na, "0")) %>%
  unite(ch23, aSp23_MEDL:bFa23_MEDL , sep = "") %>% 
  unite(ch24, cSm24_MB_SS:cSm24_MG_BW_SJ, sep = "", na.rm = TRUE) %>%
  unite(ch, ch23:ch24, sep = "")

## Only two characters would be not measured at all in 2024; still 1753 missing 
pepe_ch %>%
  filter(nchar(ch) < 3) %>%
  left_join(plants2024, by = "plantID") %>%
  filter(isTransplant == 1)

```


```{r}
## After a few more years of data, might be useful. Not sure why the line for first set of Spring isn't at 1
surv2023_2024 %>%
  filter(transplantSeason %in% c("Spring", "Fall")) %>% 
  filter(transectID != 16) %>%
  mutate(Date = as.Date(date)) %>%
  arrange(Date) %>%
  mutate(surv = case_when(heightInCentimeters > 0 ~ 1,
                          heightInCentimeters == 0 ~ 0)) %>%
  ggplot(  aes(Date, surv, color = transplantSeason)) +
    geom_point(pch = "|")+
    geom_smooth(method = "glm", 
                method.args = list(family = "binomial"), 
                se = TRUE) +
    scale_color_manual(values = c("darkgreen","violet")) +
  theme_bw()


## Percent survival at each date
surv2023_2024 %>%
  filter(transplantSeason %in% c("Spring", "Fall")) %>% 
  filter(transectID != 16) %>%
  # mutate(Date = as.Date(date)) %>%
  # arrange(Date) %>%
  filter(date == "2024-06-24") %>%
  mutate(surv = case_when(heightInCentimeters > 0 ~ 1,
                          heightInCentimeters == 0 ~ 0)) %>% 
  group_by(transplantSeason, date, transectID, recordedBy) %>%
  summarise(PercSurv = sum(surv)/5) %>%
  ggplot(  aes(date, PercSurv, color = transplantSeason)) +
    geom_boxplot(outlier.shape = NA )+
    geom_point(position = position_jitterdodge(jitter.height = 0.01), pch = 21)+
    scale_color_manual(values = c("darkgreen","violet")) +
    theme_bw()


## How many survived by season
surv2023_2024 %>%
  filter(date == "2024-06-24") %>%
  filter(transectID != 16) %>%


surv2023_2024 <- surv2023_2024 %>%
  distinct(Season,date,plantID,transectID,Transect_position,x,y,  .keep_all = TRUE)
  
## Where are there double records? the 118 and the other duplicated one? spring?  
## PlantID 982 is for two different plants, both in there twice
# Plant 118 is in twice as slot 8 with 3.75 and 4.75 Spring, same measurements. 
## Plant 982 has 0.75 and 1.75 for both slot 3 and 4, need new plantID for one of them - Rick is doing
# Transect 34, slots 2, 5, and 8 repeated. 8 has two different measurements - because Adriana and Michelle did a second recording of them! Adding the other two with a different recorder. Rick is doing


# Fix above and rerun
surv2023_2024 %>%
  filter(Season %in% c("Spring", "Fall")) %>% 
  mutate(date = case_when(date == "2024-06-25" ~ "2024-06-24",
                          TRUE ~ date)) %>%
  mutate(Date = as.Date(date)) %>%
  arrange(Date) %>%
  mutate(surv = case_when(heightInCentimeters > 0 ~ 1,
                          heightInCentimeters == 0 ~ 0)) %>% 
  group_by(Season, Date, transectID, recordedBy) %>%
  mutate(PercSurv = sum(surv)/5) %>%
  filter(PercSurv > 1) %>%
  select(c(plantID, date, heightInCentimeters, recordedBy, transectID,Transect_position, x,y,PercSurv)) %>%
  arrange(Season,Transect_position) %>%
  print(n=30)

################################## Should all be fixed in database and come out clean ###############################

surv2023_2024 %>%
  filter(Season %in% c("Spring", "Fall")) %>%  
  mutate(date = case_when(date == "2024-06-25" ~ "2024-06-24",
                          TRUE ~ date)) %>%
  mutate(Date = as.Date(date)) %>%
  arrange(Date) %>%
  mutate(surv = case_when(heightInCentimeters > 0 ~ 1,
                          heightInCentimeters == 0 ~ 0)) %>%
  mutate(date = case_when(date == "2024-06-25" ~ "2024-06-24",
                          TRUE ~ date)) %>%
  filter(date == "2024-06-24") %>%
  ggplot(  aes(transectID, surv, color = Season)) +
    geom_point(pch = "|")+
    geom_smooth(method = "glm", 
                method.args = list(family = "binomial"), 
                se = TRUE) +
    scale_color_manual(values = c("darkgreen","violet")) +
    theme_bw()

surv2023_2024 %>%
  filter(Season %in% c("Spring", "Fall")) %>% 
  mutate(date = case_when(date == "2024-06-25" ~ "2024-06-24",
                          TRUE ~ date)) %>% 
  mutate(Date = as.Date(date)) %>%
  arrange(Date) %>%
  mutate(surv = case_when(heightInCentimeters > 0 ~ 1,
                          heightInCentimeters == 0 ~ 0)) %>%
  filter(!(Season == "Fall" & Date == "2023-05-31")) %>%
  mutate(date = case_when(date == "2024-06-25" ~ "2024-06-24",
                          TRUE ~ date)) %>%
  filter(date == "2024-06-24") %>%
  ggplot(  aes(transectID, surv)) +
    geom_point(pch = "|")+
    geom_smooth(method = "glm", 
                method.args = list(family = "binomial"), 
                se = TRUE) +
    theme_bw()

## Survival depend on size or reproduction?

surv2023_2024 %>%
  filter(Season %in% c("Spring", "Fall")) %>%  
  mutate(InitialHeight = case_when(Season=="Spring" & date ==  "2023-05-31" ~ heightInCentimeters,
                                   Season=="Fall" & date == "2023-10-16" ~ heightInCentimeters)) %>%
  mutate(surv = case_when(heightInCentimeters > 0 ~ 1,
                          heightInCentimeters == 0 ~ 0)) %>%
  filter(!(Season == "Fall" & date == "2023-05-31")) %>%
  mutate(date = case_when(date == "2024-06-25" ~ "2024-06-24",
                          TRUE ~ date)) %>%
  filter(date == "2024-06-24") %>%
  ggplot(  aes(InitialHeight, surv)) +
    geom_point(pch = "|")+
    geom_smooth(method = "glm", 
                method.args = list(family = "binomial"), 
                se = TRUE) +
    theme_bw()

## Need initial height
surv_wide_perfectdetection <- surv2023_2024 %>%
  mutate(date = case_when(date == "2024-06-25" ~ "2024-06-24",
                          TRUE ~ date)) %>%
  mutate(Date = as.Date(date)) %>%
  arrange(Date) %>%
  mutate(date2 = gsub("[[:punct:]]", "", surv2023_2024$date))  %>%
  pivot_wider(names_from = c(date2),
              values_from = heightInCentimeters,
              id_cols = c(plantID,Season,transectID, Block),
              names_prefix = "Date",
               ,values_fn = function(x) max(x,na.rm = TRUE)  ## Because why? why are there double for the same date and observers?
              ) %>%
  arrange(transectID,Block,Season) %>%
  mutate(InitialHeight = case_when(Season == "Spring" ~ Date20230531,
                                   Season == "Fall" ~ Date20231016))

## What?!?! Now there are more measurements for fall in the spring! that's wrong!!! 
surv_wide_perfectdetection %>%
  filter(Season %in% c("Spring","Fall")) %>%
  filter(Season == "Fall" & !is.na(Date20230531))

surv_wide_perfectdetection %>%
  filter(Season %in% c("Fall","Spring")) %>%
  mutate(surv = case_when('2024-06-24' > 0 ~ 1,
                          '2024-06-24' == 0 ~ 0)) %>%
  group_by(transectID, Block, Season) %>%
  summarise(percSurv = sum(surv)/5)
  ggplot(  aes(Season, surv))

```



## Survival by transplant time  
```{r}

surv_transplants <- surv2023_2024 %>%
  filter(Season %in% c("Spring", "Fall")) %>%  
  mutate(InitialHeight = case_when(Season=="Spring" ~ heightInCentimeters[date == "2023-05-31"],
                                   Season=="Fall" ~ heightInCentimeters[date == "2023-10-16"])) %>%
  mutate(Date = as.Date(date)) %>%
  arrange(Date) %>%
  mutate(surv = case_when(heightInCentimeters > 0 ~ 1,
                          heightInCentimeters == 0 ~ 0)) %>%
  filter()


glm.season <- glm()



glm.list <- list(brnull,br1a,br2,br3,br1b,br1,br2a, br3a)
glm.names <- as.character(unlist(lapply(glm.list,formula)))
(glm.results <- aictab(glm.list, modnames=glm.names))

```


### Run with rmark  
```{r}

```





### Examples for true models

Gimenez 2020 <https://www.youtube.com/watch?v=VR8qdNvCaGk>     
phi(.), p(.)   
```{r}

# Likelihood
for(i in 1:nind){
  
  # Define latent state at first capture
  z[i,f[i]] <- 1  # vector of when first encounter happened, always alive when first detected
  
  for(t in (f[i]+1):n.occasions){  # loop over time from the second encounter onward
    # State process
    z[i,t] ~ dbern(phi * z[i,t-1]) # will be alive on first encounter, then Bernoulli
    
    # Obervation process
    y[i,t] ~ dbern(p * z[i,t]) # true state times prob of detection
    
    } # t time
  
} # loop over all i individuals

phi ~ dunif(0,1) # prior for survival
p ~ dunif(0,1) # Prior for recapture




```

CJS phi(t), p(t)   
```{r}

# Likelihood
for(i in 1:nind){
  
  # Define latent state at first capture
  z[i,f[i]] <- 1  # vector of when first encounter happened, always alive when first detected
  
  for(t in (f[i]+1):n.occasions){  # loop over time from the second encounter onward
    # State process
    z[i,t] ~ dbern(phi[t-1] * z[i,t-1]) # will be alive on first encounter, then Bernoulli, survival for each time interval
    
    # Obervation process
    y[i,t] ~ dbern(p[t-1] * z[i,t]) # true state times prob of detection, detection for each time interval
    
    } # t time
  
} # loop over all i individuals

## Need prior for each occasion
for(t in 1:n.occasions-1){
  phi[t] ~ dunif(0,1) # prior for survival
  p[t] ~ dunif(0,1) # Prior for recapture
}




```


Differences among groups, individual covariates     
```{r}


# Likelihood
for(i in 1:nind){
  
  # Define latent state at first capture
  z[i,f[i]] <- 1  # vector of when first encounter happened, always alive when first detected
  
  for(t in (f[i]+1):n.occasions){  # loop over time from the second encounter onward
    # State process
    z[i,t] ~ dbern(phi[i,t-1] * z[i,t-1]) # will be alive on first encounter, then Bernoulli, survival for each time interval
    
    # Obervation process
    y[i,t] ~ dbern(p[i,t-1] * z[i,t]) # true state times prob of detection, detection for each time interval
    
    } # t time
  
} # loop over all i individuals

## Need prior for each occasion
for(i in 1:nind){
  for(t in 1:(n.occasions-1)){  # in interval from t to t+1
    phi[i,t] ~ dunif(0,1) # prior for survival
    p[i,t] ~ dunif(0,1) # Prior for recapture
  }
}

```

Apply constraints on parameters, phi(.), p(.)   
```{r}

# Priors and constraints 
for(i in 1:nind){
  for(t in 1:(n.occasions-1)){
    phi[i,t] <- mean.phi   # not a 'mean' but a constant
    p[i,t] <- mean.p       # not a 'mean' but a constant
  }
}  

# Prior  
mean.phi ~ dunif(0,1)
mean.p ~ dunif(0,1)


```



Simulate capture-history matrix   
```{r}
n.occasions <- 6
marked <- rep(50, n.occasions-1)   # Annual number of newly marked individuals
phi <- rep(0.65, n.occasions-1)
p <- rep(0.4, n.occasions-1)

# Define matrices with survival and recapture probs
PHI <- matrix(phi, ncol = n.occasions-1, nrow = sum(marked))
P <- matrix(p, ncol = n.occasions-1, nrow=sum(marked))

simul.cjs <- function(PHI, P, marked){
  n.occasions <- dim(PHI)[2] + 1
  CH <- matrix(0, ncol = n.occasions, nrow = sum(marked))
  
  # Define a vector with the occasion of marking
  mark.occ <- rep(1:length(marked), marked[1:length(marked)])
  # Fill the CH matrix 
  for(i in 1:sum(marked)){
    CH[i, mark.occ[i]] <- 1     # First is a 1
    if(mark.occ[i] == n.occasions) next
      for(t in (mark.occ[i]+1):n.occasions){
        # Bernoulli trial for survival
        sur <- rbinom(1,1,PHI[i,t-1])
        if(sur==0) break   # If dead, move to next individual
        # Bernoulli for recapture
        rp <- rbinom(1,1,P[i,t-1])
        if(rp==1) CH[i,t] <- 1  # If you recaptured, it gets a '1'
      } # t
  } # i
return(CH)
  }

## Simulate!
sim1 <- simul.cjs(PHI, P, marked)

# Create vector with occasion of marking  
get.first <- function(x) min(which(x != 0))
f <- apply(sim1, 1, get.first)  ## Apply across rows


## BUGS  
SimulCJS <- 
  paste("
model {
  
  # Constraints
  for(i in 1:nind){
    for(t in 1:(n.occasions-1)){
      phi[i,t] <- mean.phi
      p[i,t] <- mean.p
    }
  }
  
  # Priors
  mean.phi ~ dunif(0,1)
  mean.p ~ dunif(0,1)
  
  # Likelihood
  for(i in 1:nind){
  
    # Define latent state at first capture
    z[i,f[i]] <- 1
    for(t in (f[i]+1):n.occasions){
    
      # State process
      z[i,t] ~ dbern(phi[i,t-1] * z[i, t-1])
      
      # Observation process
      y[i,t] ~ dbern(p[i,t-1] * z[i,t])
    }
  }
}

")

writeLines(SimulCJS, "SimulCJS.jags")

jags.data <- list(y = sim1,
                  f= f,
                  nind = nrow(sim1),
                  n.occasions = ncol(sim1))

# Set 'good' initial values
z.inits <- function(ch){
  state <- ch
  state[state==0] <- 1
  get.first <- function(x){ min(which(x != 0)) }
  f <- apply(ch, 1, get.first)
    for(i in 1:nrow(ch)){
      state[i, 1:f[i]] <- NA
    }
  return(state)
}

inits <- function(){list(mean.phi = runif(1,0,1),
                         mean.p = runif(1,0,1),
                         z = z.inits(sim1))}   # The latent states (alive, dead) also need initial values
  # Could monitor the latent states (if we have missing data)

parameters <- c("mean.phi","mean.p")

# MCMC settings
ni <- 1000
nt <- 1
nb <- 500
nc <- 3

cjs.c.c <- jags(data = jags.data,
                inits = inits,
                parameters.to.save = parameters,
                model.file = "SimulCJS.jags",
                n.chains = nc,
                n.thin = nt,
                n.iter = ni, n.burnin = nb,
                working.directory = getwd())

print(cjs.c.c, digits = 3)

## This is around 50 minutes

# save(cjs.c.c, file = )
```



Second part <https://www.youtube.com/watch?v=vYWj50Sj-q4>  
Random time effects
```{r}

n.occasions >- 12
marked <- rep(50, n.occasions-1)  ## Annual number of newly marked individuals
mean.phi <- 0.65
sigma2.phi <- 1
p <- rep(0.4, n.occasions-1)

## Annual survival probabilities on logistic scale
logit.phi <- rnorm(n.occasions-1, qlogis(mean.phi), sigma2.phi^0.5)
logit.phi
phi <- plogis(logit.phi)
phi
```


https://www.youtube.com/watch?v=vYWj50Sj-q4 
stopped at Minute 29



Tomst data logger  
Put in issue on GitHub
```{r}

# install.packages("myClim")


tms.f <- mc_read_files(c("C:/Users/deprengm/Denver Botanic Gardens/Conservation - General/AllProjectsBySpecies/Penstemon-penlandii/Penstemon-penlandii_Projects/Tri-State_lolly_TOMSTdatalogger/data_95135950_2024_06_24_0.csv",
                         "C:/Users/deprengm/Denver Botanic Gardens/Conservation - General/AllProjectsBySpecies/Penstemon-penlandii/Penstemon-penlandii_Projects/Tri-State_lolly_TOMSTdatalogger/data_95135951_2024_06_24_0.csv",
                         "C:/Users/deprengm/Denver Botanic Gardens/Conservation - General/AllProjectsBySpecies/Penstemon-penlandii/Penstemon-penlandii_Projects/Tri-State_lolly_TOMSTdatalogger/data_95135952_2024_06_24_0.csv"),
                       dataformat_name = "TOMST", silent = TRUE)


tms.fs <- mc_read_files(paths = "C:/Users/deprengm/Denver Botanic Gardens/Conservation - General/AllProjectsBySpecies/Penstemon-penlandii/Penstemon-penlandii_Projects/Tri-State_lolly_TOMSTdatalogger",
                        dataformat_name = "TOMST")

```

